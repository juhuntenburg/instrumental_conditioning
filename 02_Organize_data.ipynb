{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.io as spio\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from glob import glob\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sns.set_style('ticks')\n",
    "sns.set_context('talk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_dir = '/home/julia/data/ict/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loadmat(filename):\n",
    "    '''\n",
    "    this function should be called instead of direct spio.loadmat\n",
    "    as it cures the problem of not properly recovering python dictionaries\n",
    "    from mat files. It calls the function check keys to cure all entries\n",
    "    which are still mat-objects\n",
    "    \n",
    "    from: `StackOverflow <http://stackoverflow.com/questions/7008608/scipy-io-loadmat-nested-structures-i-e-dictionaries>`_\n",
    "    '''\n",
    "    data = spio.loadmat(filename, struct_as_record=False, squeeze_me=True)\n",
    "    return data      \n",
    "\n",
    "def todict(matobj):\n",
    "    '''\n",
    "    A recursive function which constructs from matobjects nested dictionaries\n",
    "    '''\n",
    "    dict = {}\n",
    "    for strg in matobj._fieldnames:\n",
    "        elem = matobj.__dict__[strg]\n",
    "        if isinstance(elem, spio.matlab.mio5_params.mat_struct):\n",
    "            dict[strg] = _todict(elem)\n",
    "        else:\n",
    "            dict[strg] = elem\n",
    "    return dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Organize data per mouse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(data_dir+\"hf2.csv\", index_col=0)\n",
    "df = df[df['quality']==1]\n",
    "df = df[df['licks']==1]\n",
    "df = df[df['finalTimes']==1]\n",
    "\n",
    "# Excludes 4 datasets based on quality, availability of lick data and using final time periods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mice = ['SHA', 'TAY', 'UUU', 'VVV', 'WEY', 'YOU']\n",
    "for m in mice:\n",
    " \n",
    "    df_mouse = pd.DataFrame(columns=['dataset', 'day', 'inf',\n",
    "                                     'num', 'type', 'odor', 'performance', \n",
    "                                     'start', 'end',\n",
    "                                     'odor_start', 'iti_start', \n",
    "                                     'licks', 'gpmt', 'rpmt',\n",
    "                                     'emg', 'body', 'neck'])\n",
    "    \n",
    "    mouse_files = df[df['fnames'].str.contains(m)]['fnames']\n",
    "    for f in mouse_files:\n",
    "        mat = loadmat(data_dir+\"orig/{}.mat\".format(f))\n",
    "        trials = [todict(mat[\"lick_data\"][i]) for i in range(len(mat[\"lick_data\"]))]\n",
    "        \n",
    "        for t in trials:\n",
    "            t['dataset'] = f\n",
    "            t['day'] = df[df['fnames']==f]['DfromRev'].values[0]\n",
    "            t['inf'] = df[df['fnames']==f]['inf'].values[0]\n",
    "            \n",
    "            # change arrays to lists to fit in df\n",
    "            for i in ['licks', 'gpmt', 'rpmt', 'emg', 'body', 'neck']:\n",
    "                t[i] = [t[i]]\n",
    "            df_mouse= df_mouse.append(pd.DataFrame.from_dict(t), sort=True)\n",
    "        \n",
    "    df_mouse = df_mouse.reset_index(drop=True)\n",
    "    df_mouse.to_pickle(data_dir+\"mice/{}.pkl\".format(m))\n",
    "    \n",
    "    df_mouse_small = df_mouse.filter(['dataset', 'day', 'inf', 'num', 'type', 'odor', 'performance',\n",
    "                                      'start', 'end', 'odor_start', 'iti_start'])\n",
    "    df_mouse_small.to_csv(data_dir+\"mice/{}_small.csv\".format(m))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make one dataframe containing per trial data of all mice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_all = pd.DataFrame(columns=['dataset', 'day', 'inf', 'num', 'type', 'odor', 'performance',\n",
    "                                'start', 'end', 'odor_start', 'iti_start'])\n",
    "\n",
    "for m in mice:\n",
    "    df_mouse = pd.read_csv(data_dir+\"mice/{}_small.csv\".format(m), index_col=0)\n",
    "    df_all = df_all.append(df_mouse)\n",
    "\n",
    "df_all = df_all.reset_index(drop=True)\n",
    "df_all.to_csv(data_dir+\"all_mice.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Align licks and photometry to odor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mice = ['SHA', 'TAY', 'UUU', 'VVV', 'WEY', 'YOU']\n",
    "\n",
    "for i in ['gpmt']:# ['licks', 'gpmt', 'rpmt']:\n",
    " \n",
    "    df_all_odor = pd.DataFrame(index=np.arange(-5000, 15000))\n",
    "    for m in mice:\n",
    "        \n",
    "        df_mouse = pd.read_pickle(data_dir+\"mice/{}.pkl\".format(m)).filter(['odor_start', i])\n",
    "        ts_odor = []\n",
    "        for row in range(len(df_mouse)):\n",
    "            ts = df_mouse.loc[row, i]\n",
    "            zero_idx = df_mouse.loc[row, 'odor_start']\n",
    "            ts_odor.append(pd.Series(name=\"{}_{}\".format(m,row), data=ts,\n",
    "                                    index=np.arange(-zero_idx, -zero_idx+ts.shape[0])))\n",
    "        df_odor = pd.DataFrame(index=np.arange(-5000, 15000))        \n",
    "        df_odor = df_odor.join(ts_odor, how='left')\n",
    "        np.save(\"/home/julia/data/ict/odor_aligned/{}_{}.npy\".format(m, i), np.asarray(df_odor))\n",
    "\n",
    "        df_all_odor = df_all_odor.join(df_odor, how='left')\n",
    "    np.save(\"/home/julia/data/ict/odor_aligned/all_{}.npy\".format(i), np.asarray(df_all_odor))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Align licks and photometry to ITI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mice = ['SHA', 'TAY', 'UUU', 'VVV', 'WEY', 'YOU']\n",
    "\n",
    "for i in ['licks']: #, ['licks', 'gpmt', 'rpmt']:\n",
    " \n",
    "    df_all_iti = pd.DataFrame(index=np.arange(-10000, 10000))\n",
    "    for m in mice:\n",
    "        \n",
    "        df_mouse = pd.read_pickle(data_dir+\"mice/{}.pkl\".format(m)).filter(['iti_start', i])\n",
    "        ts_iti = []\n",
    "        for row in range(len(df_mouse)):\n",
    "            ts = df_mouse.loc[row, i]\n",
    "            zero_idx = df_mouse.loc[row, 'iti_start']\n",
    "            ts_iti.append(pd.Series(name=\"{}_{}\".format(m,row), data=ts,\n",
    "                                    index=np.arange(-zero_idx, -zero_idx+ts.shape[0])))\n",
    "        df_iti = pd.DataFrame(index=np.arange(-10000, 10000))        \n",
    "        df_iti = df_iti.join(ts_iti, how='left')\n",
    "        np.save(\"/home/julia/data/ict/iti_aligned/{}_{}.npy\".format(m, i), np.asarray(df_iti))\n",
    "\n",
    "        df_all_iti = df_all_iti.join(df_iti, how='left')\n",
    "    np.save(\"/home/julia/data/ict/iti_aligned/all_{}.npy\".format(i), np.asarray(df_all_iti))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
